{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIME.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxfZUiVMOwhh",
        "colab_type": "text"
      },
      "source": [
        "# Przykład dla danych tekstowych (dwie klasy)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nosarzewski/TUS/blob/master/LIME_not_run.ipynb)\n",
        "\n",
        "W tym przykładzie wykorzystamy zbiór [20 newsgroups text dataset](https://scikit-learn.org/stable/datasets/#the-20-newsgroups-text-dataset).\n",
        "\n",
        "Zawiera on dane tekstowe dla ponad 18.000 dokumentów, pogrupowanych w 20 bloków tematycznych.\n",
        "\n",
        "Skorzystamy z wyłącznie dwóch grup: chrześcijaństwo oraz ateizm.\n",
        "\n",
        "## 1. Wczytanie bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9S44PDpRmOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install lime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti3qrmLCOZ45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lime\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.ensemble\n",
        "import sklearn.metrics\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UK1gst5OroG",
        "colab_type": "text"
      },
      "source": [
        "## 2. Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwyCucSP_aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['alt.atheism', 'soc.religion.christian']\n",
        "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset = 'test', categories = categories)\n",
        "class_names = ['atheism', 'christian']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQHoKiHQQ_q",
        "colab_type": "text"
      },
      "source": [
        "## 3. Budowa modelu\n",
        "Wykorzystamy las losowy (*aka stochastic jungle*) do predykcji.\n",
        "\n",
        "Niestety dane tekstowe w surowej postaci nie nadają się do wykorzystania przez model. Dletego do reprezentacji tekstów wykorzystamy [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (term frequency - inverse term frequency), które wskazuje jak ważne jest dane słowo w dokumencie:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLtvVAyiQkdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase = False)\n",
        "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "test_vectors = vectorizer.transform(newsgroups_test.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNh5T4UsRv9-",
        "colab_type": "text"
      },
      "source": [
        "Następnie wytrenujmy nasz las losowy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIcofCtGSCxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = sklearn.ensemble.RandomForestClassifier(n_estimators = 500)\n",
        "rf.fit(train_vectors, newsgroups_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEJ5oGBSgJc",
        "colab_type": "text"
      },
      "source": [
        "Skoro mamy już model, to dokonajmy predykcji:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnWQ9fQUSmnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = rf.predict(test_vectors)\n",
        "sklearn.metrics.f1_score(newsgroups_test.target, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJ3HSa6S1yS",
        "colab_type": "text"
      },
      "source": [
        "Nasz model osiąga wysoką wartość F1, co powinno świadczyć o dobrej jakości modelu.\n",
        "\n",
        "Jednakże, [tutorial sklearn](https://scikit-learn.org/stable/datasets/#filtering-text-for-more-realistic-training) wskazuje, że naiwny klasyfikator bayesowski jest przeuczony w stosunku do danych i wychwytuje zależności, które nie mają uzasadnienia. Sprawdźmy, czy dla dla naszego lasu losowego także jest to prawda.\n",
        "\n",
        "## 4. Wyjaśnianie modelu z wykorzystaniem LIME\n",
        "\n",
        "Nasz model został wyuczony na wartościach TF-IDF, podczas gdy LIME działa na samych słowach. \n",
        "\n",
        "Wykorzystamy zdolności pakietu sklearn aby obejść tę niedogodność:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEIQV_DUTiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "c = make_pipeline(vectorizer, rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0joCuFBUUmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(c.predict_proba([newsgroups_test.data[0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSd0FeAGUelt",
        "colab_type": "text"
      },
      "source": [
        "Teraz możemy dokonać wyjaśnienia modelu za pomocą LIME:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_I3IKTPUlrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names = class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbPcwXhjU3AR",
        "colab_type": "text"
      },
      "source": [
        "Dokonajmy wytłumaczenia dla dokumentu nr 83. Model wykorzystywany do wyjaśniania powinien koszystać z co najwyżej 6 cech (zmiennych)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcwO69xRVDEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 83\n",
        "exp = explainer.explain_instance(newsgroups_test.data[idx], \n",
        "                                 c.predict_proba, \n",
        "                                 num_features = 6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
        "print('True class: %s' % class_names[newsgroups_test.target[idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRbgmPfeVamN",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy z czego korzystał nasz model podczas prognozowania:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDVD3-RPVaBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp.as_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntUUYYNUWEZJ",
        "colab_type": "text"
      },
      "source": [
        "Widzimy, że dwa najważniejsze słowa to 'Posting' oraz 'Host'. Jeśli byśmy je usunęli to prawdopodobieństwo tego, że dokument należy do klasy 'christian' powinno wzrosnąć o 27 p.p.\n",
        "\n",
        "Sprawdźmy czy tak rzeczywiście jest!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5-uGFuIWZp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
        "tmp = test_vectors[idx].copy()\n",
        "tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
        "tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
        "print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
        "print('Difference:', round(rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1], 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmsUJjciXMB0",
        "colab_type": "text"
      },
      "source": [
        "## 5. Wizualizacja\n",
        "\n",
        "Spróbujmy zwizualizować nasze wyniki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhRAfJWNXQ9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTYYqWMqXdFR",
        "colab_type": "text"
      },
      "source": [
        "Możemy też pokazać wpływ słów w sposób bardziej zrozumiały dla laika."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9PYgwHXWxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp.show_in_notebook(text = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V18vJ5ryXp3i",
        "colab_type": "text"
      },
      "source": [
        "Możemy także zaznaczyć słowa mające największy wpływ na predykcję w samym oryginalnym dokumencie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOHHDnJQXleD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp.show_in_notebook(text = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgTv5YLRX1PL",
        "colab_type": "text"
      },
      "source": [
        "Widzimy, że choć zdawało się, że nasz model działa dobrze (osiąga wysokie wartości miary F), to robi to w sposób całkowicie nieuzasadniony dla człowieka."
      ]
    }
  ]
}